{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MT2i98HkvoNL",
        "outputId": "1053cdbb-ae4b-41da-b768-be41ad36bf6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.7/409.7 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq langchain-community"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Document Splitter"
      ],
      "metadata": {
        "id": "u37ZM95b3ErZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = \"\"\"\n",
        "Text mining, text data mining (TDM) or text analytics is the process of deriving high-quality information from text.\n",
        "It involves \"the discovery by computer of new, previously unknown information, by automatically extracting information from different written resources.\"\n",
        "[1] Written resources may include websites, books, emails, reviews, and articles.\n",
        "High-quality information is typically obtained by devising patterns and trends by means such as statistical pattern learning.\n",
        "According to Hotho et al. (2005) we can distinguish between three different perspectives of text mining: information extraction, data mining,\n",
        "and a knowledge discovery in databases (KDD) process.\n",
        "[2] Text mining usually involves the process of structuring the input text (usually parsing,\n",
        "along with the addition of some derived linguistic features and the removal of others,\n",
        "and subsequent insertion into a database), deriving patterns within the structured data, and finally evaluation and interpretation of the output.\n",
        "'High quality' in text mining usually refers to some combination of relevance, novelty, and interest.\n",
        "Typical text mining tasks include text categorization, text clustering, concept/entity extraction,\n",
        "production of granular taxonomies, sentiment analysis, document summarization, and entity relation modeling (i.e., learning relations between named entities).\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "MEx47kPcwKSw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq requests"
      ],
      "metadata": {
        "id": "h49chsAZ2rzt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "3JSKEwOd1BEk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "import requests"
      ],
      "metadata": {
        "id": "y8SQhNTP2Oz6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_data = requests.get(\"https://api.smith.langchain.com/openapi.json\").json()"
      ],
      "metadata": {
        "id": "OJWR88gb2WFd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 300\n",
        "chunk_overlap = 30\n",
        "separators: list[str] = ['n\\n', '\\n', ' ', '']"
      ],
      "metadata": {
        "id": "I_N7UDWy1Ge1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char_text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap,\n",
        "    separators=separators,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False\n",
        ")"
      ],
      "metadata": {
        "id": "HAO78LYH1bMq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_output = char_text_splitter.split_text(text_data)"
      ],
      "metadata": {
        "id": "eD_FSa961o1g"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMBx3yml1tJR",
        "outputId": "0f1df919-a68d-4292-8367-b24f0dd46efe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Text mining, text data mining (TDM) or text analytics is the process of deriving high-quality information from text. \\nIt involves \"the discovery by computer of new, previously unknown information, by automatically extracting information from different written resources.\"',\n",
              " '[1] Written resources may include websites, books, emails, reviews, and articles. \\nHigh-quality information is typically obtained by devising patterns and trends by means such as statistical pattern learning.',\n",
              " 'According to Hotho et al. (2005) we can distinguish between three different perspectives of text mining: information extraction, data mining, \\nand a knowledge discovery in databases (KDD) process.\\n[2] Text mining usually involves the process of structuring the input text (usually parsing,',\n",
              " 'along with the addition of some derived linguistic features and the removal of others, \\nand subsequent insertion into a database), deriving patterns within the structured data, and finally evaluation and interpretation of the output.',\n",
              " \"'High quality' in text mining usually refers to some combination of relevance, novelty, and interest.\\nTypical text mining tasks include text categorization, text clustering, concept/entity extraction,\",\n",
              " 'production of granular taxonomies, sentiment analysis, document summarization, and entity relation modeling (i.e., learning relations between named entities).']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Embedding"
      ],
      "metadata": {
        "id": "UQUGWcR53IHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "QTn4qRJg1vfN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    model_kwargs={'device': 'cpu'},\n",
        "    encode_kwargs={'normalize_embeddings': False}\n",
        ")'''\n",
        "embeddings = HuggingFaceEmbeddings()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuaa-1zO4QIc",
        "outputId": "198b5bea-bd86-4b95-b394-478ec0b74d0b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-43-68b1626ae145>:6: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
            "  embeddings = HuggingFaceEmbeddings()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector_embeddings = embeddings.embed_query(text_data)"
      ],
      "metadata": {
        "id": "Ek17tkFb4X56"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vector_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41Hcjh6Y4kds",
        "outputId": "032fc010-b80b-4309-aa90-49018ff532e2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Database"
      ],
      "metadata": {
        "id": "dMkf0xu64z0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4IDSScP7Xbf",
        "outputId": "c7ff22b2-79e5-4189-eeab-5c1caa6305da"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/298.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader"
      ],
      "metadata": {
        "id": "I7ie_oKv7D5C"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_url = 'https://arxiv.org/pdf/2312.16862.pdf'\n",
        "pdf_loader = PyPDFLoader('/content/Alice Clark CV.pdf')\n",
        "pdf_pages = pdf_loader.load()"
      ],
      "metadata": {
        "id": "uxna-KP27EnP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(pdf_pages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XphIHfH7WBU",
        "outputId": "a71389cf-0623-4ed4-fc60-8c5b9261d9bd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(pdf_pages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRzQKNdn7dQM",
        "outputId": "5875af1c-849c-418f-f6b7-289e2632eb27"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "IvZa0PI--5WJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 50\n",
        "chunk_overlap = 20\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=chunk_size,\n",
        "    chunk_overlap=chunk_overlap,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False\n",
        ")"
      ],
      "metadata": {
        "id": "3yPA__zE_Edf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = splitter.split_documents(pdf_pages)"
      ],
      "metadata": {
        "id": "vIuuVHZN7jpH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(docs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "gi_mpxOB7zVm",
        "outputId": "7f7b9f1e-256b-497c-b0b6-713664f0e1c6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_core.documents.base.Document"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.documents.base.Document</b><br/>def __init__(page_content: str, **kwargs: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/langchain_core/documents/base.py</a>Class for storing a piece of text and associated metadata.\n",
              "\n",
              "Example:\n",
              "\n",
              "    .. code-block:: python\n",
              "\n",
              "        from langchain_core.documents import Document\n",
              "\n",
              "        document = Document(\n",
              "            page_content=&quot;Hello, world!&quot;,\n",
              "            metadata={&quot;source&quot;: &quot;https://example.com&quot;}\n",
              "        )</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 262);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc4qBTFWKgpg",
        "outputId": "6900790a-843c-41d5-8ada-70914cfffc25"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='Alice Clark \\nAI / Machine Learning'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='Delhi, India Email me on Indeed'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='• 20+ years of experience in data handling,'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='in data handling, design, and development'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='• Data Warehouse: Data analysis, star/snow flake'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='star/snow flake scema data modelling and design'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='and design specific to'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='data warehousing and business intelligence'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='• Database: Experience in database designing,'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='database designing, scalability, back-up and'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='back-up and recovery, writing and'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='optimizing SQL code and Stored Procedures,'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='Stored Procedures, creating functions, views,'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='functions, views, triggers and indexes.'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='Cloud platform: Worked on Microsoft Azure cloud'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='Azure cloud services like Document DB, SQL Azure,'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='DB, SQL Azure,'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='Stream Analytics, Event hub, Power BI, Web Job,'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='Power BI, Web Job, Web App, Power BI, Azure data'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='BI, Azure data lake'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='analytics(U-SQL) \\nWilling to relocate anywhere'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='WORK EXPERIENCE \\nSoftware Engineer'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='Microsoft – Bangalore, Karnataka'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='January 2000 to Present'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='1. Microsoft Rewards Live dashboards:'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='Description: - Microsoft rewards is loyalty'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='rewards is loyalty program that rewards Users for'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='rewards Users for browsing and shopping'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='online. Microsoft Rewards members can earn points'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='can earn points when searching with Bing,'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='with Bing, browsing with'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='Microsoft Edge and making purchases at the Xbox'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='at the Xbox Store, the Windows Store and the'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='Store and the Microsoft'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='Store. Plus, user can pick up bonus points for'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='up bonus points for taking daily quizzes and'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='daily quizzes and tours on the Microsoft'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='rewards website. Rewards live dashboards gives a'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='dashboards gives a live picture of usage'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='picture of usage world-wide and by'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='markets like US, Canada, Australia, new user'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='Australia, new user registration count,'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='registration count, top/bottom performing rewards'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='performing rewards'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='offers, orders stats and weekly trends of user'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='trends of user activities, orders and new user'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='orders and new user registrations. the'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='PBI tiles gets refreshed in different frequencies'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='frequencies starting from 5 seconds to 30'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='5 seconds to 30 minutes.'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='Technology/Tools used \\n \\nEDUCATION'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='Indian Institute of Technology – Mumbai \\n2001'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='2001 \\n \\nSKILLS'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='Machine Learning, Natural Language Processing,'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 0}, page_content='Processing, and Big Data Handling'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 1}, page_content='ADDITIONAL INFORMATION \\nProfessional Skills'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 1}, page_content='• Excellent analytical, problem solving,'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 1}, page_content='problem solving, communication, knowledge'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 1}, page_content='knowledge transfer and interpersonal'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 1}, page_content='skills with ability to interact with individuals'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 1}, page_content='with individuals at all the levels'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 1}, page_content='• Quick learner and maintains cordial'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 1}, page_content='maintains cordial relationship with project'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 1}, page_content='with project manager and team members and'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 1}, page_content='good performer both in team and independent job'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 1}, page_content='and independent job environments'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 1}, page_content='• Positive attitude towards superiors &amp; peers'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 1}, page_content='&amp; peers'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 1}, page_content='• Supervised junior developers throughout project'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 1}, page_content='throughout project lifecycle and provided'),\n",
              " Document(metadata={'source': '/content/Alice Clark CV.pdf', 'page': 1}, page_content='and provided technical assistance')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -Uq langchain-chroma"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZA64yE7K6R7R"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma"
      ],
      "metadata": {
        "id": "mxb2Qbrk4u0v"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "nmFyv1j2-HAP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Chroma.from_documents with plain texts\n",
        "chroma_db = Chroma.from_documents(docs, embedding=embedding_model)"
      ],
      "metadata": {
        "id": "mCEceBhS6Kj8"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "TypeError: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]"
      ],
      "metadata": {
        "id": "zvazRTRJFWHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'collect all skills'\n",
        "similar_docs = chroma_db.similarity_search(query, k=4)"
      ],
      "metadata": {
        "id": "mySViqfV6qk2"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsB9JkJyQwmJ",
        "outputId": "36245b5e-1edb-4f0c-831f-c55361173e5d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'page': 0, 'source': '/content/Alice Clark CV.pdf'}, page_content='2001 \\n \\nSKILLS'),\n",
              " Document(metadata={'page': 1, 'source': '/content/Alice Clark CV.pdf'}, page_content='skills with ability to interact with individuals'),\n",
              " Document(metadata={'page': 1, 'source': '/content/Alice Clark CV.pdf'}, page_content='• Quick learner and maintains cordial'),\n",
              " Document(metadata={'page': 0, 'source': '/content/Alice Clark CV.pdf'}, page_content='performing rewards')]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l493x_3GQx1U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}