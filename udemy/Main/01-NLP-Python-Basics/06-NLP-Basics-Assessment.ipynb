{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Basics Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assessment we'll be using the short story [_An Occurrence at Owl Creek Bridge_](https://en.wikipedia.org/wiki/An_Occurrence_at_Owl_Creek_Bridge) by Ambrose Bierce (1890). <br>The story is in the public domain; the text file was obtained from [Project Gutenberg](https://www.gutenberg.org/ebooks/375.txt.utf-8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN THIS CELL to perform standard imports:\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Create a Doc object from the file `owlcreek.txt`**<br>\n",
    "> HINT: Use `with open('../TextFiles/owlcreek.txt') as f:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here:\n",
    "with open('../TextFiles/owlcreek.txt') as f:\n",
    "    doc = nlp(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AN OCCURRENCE AT OWL CREEK BRIDGE\n",
       "\n",
       "by Ambrose Bierce\n",
       "\n",
       "I.\n",
       "\n",
       "A man stood upon a railroad bridge in northern Alabama, looking down\n",
       "into the swift water twenty feet below.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run this cell to verify it worked:\n",
    "doc[:36]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. How many tokens are contained in the file?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4835"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. How many sentences are contained in the file?**<br>HINT: You'll want to build a list first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205\n"
     ]
    }
   ],
   "source": [
    "sents = [sent for sent in doc.sents]\n",
    "print(len(sents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Print the second sentence in the document**<br> HINT: Indexing starts at zero, and the title counts as the first sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A man stood upon a railroad bridge in northern Alabama, looking down\n",
      "into the swift water twenty feet below.  \n"
     ]
    }
   ],
   "source": [
    "print(sents[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 5. For each token in the sentence above, print its `text`, `POS` tag, `dep` tag and `lemma`<br>\n",
    "CHALLENGE: Have values line up in columns in the print output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         A        DET        det          a\n",
      "       man       NOUN      nsubj        man\n",
      "     stood       VERB       ROOT      stand\n",
      "      upon      SCONJ       prep       upon\n",
      "         a        DET        det          a\n",
      "  railroad       NOUN   compound   railroad\n",
      "    bridge       NOUN       pobj     bridge\n",
      "        in        ADP       prep         in\n",
      "  northern        ADJ       amod   northern\n",
      "   Alabama      PROPN       pobj    Alabama\n",
      "         ,      PUNCT      punct          ,\n",
      "   looking       VERB      advcl       look\n",
      "      down        ADV     advmod       down\n",
      "         \n",
      "      SPACE        dep          \n",
      "\n",
      "      into        ADP       prep       into\n",
      "       the        DET        det        the\n",
      "     swift        ADJ       amod      swift\n",
      "     water       NOUN       pobj      water\n",
      "    twenty        NUM     nummod     twenty\n",
      "      feet       NOUN   npadvmod       foot\n",
      "     below        ADV     advmod      below\n",
      "         .      PUNCT      punct          .\n",
      "                SPACE        dep           \n"
     ]
    }
   ],
   "source": [
    "# CHALLENGE SOLUTION:\n",
    "for token in sents[1]:\n",
    "    print(f'{token.text:>{10}} {token.pos_:>{10}} {token.dep_:>{10}} {token.lemma_:>{10}}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Write a matcher called 'Swimming' that finds both occurrences of the phrase \"swimming vigorously\" in the text**<br>\n",
    "HINT: You should include an `'IS_SPACE': True` pattern between the two words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matcher library:\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pattern and add it to matcher:\n",
    "pattern = [{'LOWER':'swimming'}, {'IS_SPACE': True, 'OP':'*'}, {'LOWER':'vigorously'}]\n",
    "\n",
    "# Add the new pattern to the Prac matcher\n",
    "matcher.add('Prac', [pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.remove('Prac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(11930998831458770932, 1274, 1277), (11930998831458770932, 3609, 3612)]\n"
     ]
    }
   ],
   "source": [
    "# Create a list of matches called \"found_matches\" and print the list:\n",
    "found_matches = matcher(doc)\n",
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prac   1274  1277 swimming\n",
      "vigorously \n",
      "Prac   3609  3612 swimming\n",
      "vigorously \n"
     ]
    }
   ],
   "source": [
    "sent_idx = []\n",
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]\n",
    "    span = doc[start:end]\n",
    "    sent_idx.append(end)\n",
    "    print(f'{string_id:{5}} {start:{5}} {end:{5}} {span.text:{20}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13\n",
      "13 36\n",
      "36 54\n",
      "54 63\n",
      "63 88\n",
      "88 138\n",
      "138 161\n",
      "161 167\n",
      "167 233\n",
      "233 274\n",
      "274 309\n",
      "309 318\n",
      "318 366\n",
      "366 423\n",
      "423 453\n",
      "453 472\n",
      "472 484\n",
      "484 505\n",
      "505 527\n",
      "527 557\n",
      "557 574\n",
      "574 594\n",
      "594 616\n",
      "616 661\n",
      "661 705\n",
      "705 713\n",
      "713 735\n",
      "735 761\n",
      "761 787\n",
      "787 821\n",
      "821 840\n",
      "840 866\n",
      "866 895\n",
      "895 909\n",
      "909 922\n",
      "922 953\n",
      "953 973\n",
      "973 981\n",
      "981 987\n",
      "987 1006\n",
      "1006 1049\n",
      "1049 1061\n",
      "1061 1109\n",
      "1109 1128\n",
      "1128 1146\n",
      "1146 1164\n",
      "1164 1179\n",
      "1179 1193\n",
      "1193 1212\n",
      "1212 1224\n",
      "1224 1237\n",
      "1237 1265\n",
      "1265 1292\n",
      "1292 1321\n",
      "1321 1360\n",
      "1360 1366\n",
      "1366 1388\n",
      "1388 1417\n",
      "1417 1488\n",
      "1488 1507\n",
      "1507 1515\n",
      "1515 1590\n",
      "1590 1630\n",
      "1630 1647\n",
      "1647 1671\n",
      "1671 1695\n",
      "1695 1718\n",
      "1718 1756\n",
      "1756 1761\n",
      "1761 1775\n",
      "1775 1779\n",
      "1779 1784\n",
      "1784 1826\n",
      "1826 1868\n",
      "1868 1875\n",
      "1875 1888\n",
      "1888 1918\n",
      "1918 1929\n",
      "1929 1944\n",
      "1944 1959\n",
      "1959 1985\n",
      "1985 1993\n",
      "1993 2015\n",
      "2015 2051\n",
      "2051 2074\n",
      "2074 2097\n",
      "2097 2113\n",
      "2113 2134\n",
      "2134 2143\n",
      "2143 2168\n",
      "2168 2174\n",
      "2174 2211\n",
      "2211 2252\n",
      "2252 2277\n",
      "2277 2303\n",
      "2303 2321\n",
      "2321 2346\n",
      "2346 2368\n",
      "2368 2402\n",
      "2402 2431\n",
      "2431 2445\n",
      "2445 2475\n",
      "2475 2502\n",
      "2502 2513\n",
      "2513 2522\n",
      "2522 2525\n",
      "2525 2551\n",
      "2551 2576\n",
      "2576 2597\n",
      "2597 2609\n",
      "2609 2641\n",
      "2641 2678\n",
      "2678 2691\n",
      "2691 2704\n",
      "2704 2723\n",
      "2723 2770\n",
      "2770 2782\n",
      "2782 2794\n",
      "2794 2822\n",
      "2822 2840\n",
      "2840 2898\n",
      "2898 2916\n",
      "2916 2966\n",
      "2966 2987\n",
      "2987 3047\n",
      "3047 3058\n",
      "3058 3069\n",
      "3069 3088\n",
      "3088 3101\n",
      "3101 3130\n",
      "3130 3163\n",
      "3163 3190\n",
      "3190 3218\n",
      "3218 3227\n",
      "3227 3256\n",
      "3256 3303\n",
      "3303 3343\n",
      "3343 3385\n",
      "3385 3390\n",
      "3390 3396\n",
      "3396 3402\n",
      "3402 3407\n",
      "3407 3409\n",
      "3409 3422\n",
      "3422 3468\n",
      "3468 3489\n",
      "3489 3509\n",
      "3509 3545\n",
      "3545 3584\n",
      "3584 3596\n",
      "3596 3617\n",
      "3617 3660\n",
      "3660 3674\n",
      "3674 3688\n",
      "3688 3702\n",
      "3702 3750\n",
      "3750 3772\n",
      "3772 3784\n",
      "3784 3828\n",
      "3828 3854\n",
      "3854 3884\n",
      "3884 3890\n",
      "3890 3907\n",
      "3907 3933\n",
      "3933 3955\n",
      "3955 3983\n",
      "3983 4023\n",
      "4023 4053\n",
      "4053 4074\n",
      "4074 4098\n",
      "4098 4127\n",
      "4127 4153\n",
      "4153 4176\n",
      "4176 4198\n",
      "4198 4210\n",
      "4210 4230\n",
      "4230 4245\n",
      "4245 4269\n",
      "4269 4284\n",
      "4284 4293\n",
      "4293 4304\n",
      "4304 4317\n",
      "4317 4338\n",
      "4338 4356\n",
      "4356 4367\n",
      "4367 4382\n",
      "4382 4416\n",
      "4416 4444\n",
      "4444 4464\n",
      "4464 4497\n",
      "4497 4515\n",
      "4515 4533\n",
      "4533 4546\n",
      "4546 4572\n",
      "4572 4596\n",
      "4596 4628\n",
      "4628 4639\n",
      "4639 4658\n",
      "4658 4668\n",
      "4668 4713\n",
      "4713 4740\n",
      "4740 4749\n",
      "4749 4757\n",
      "4757 4805\n",
      "4805 4835\n"
     ]
    }
   ],
   "source": [
    "for sent in sents:\n",
    "    print(sent.start, sent.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1277, 3612]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Print the text surrounding each found match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By diving I could evade the bullets and, swimming\n",
      "vigorously, reach the bank, take to the woods and get away home.  \n",
      "\n",
      "The hunted man saw all this over his shoulder; he was now swimming\n",
      "vigorously with the current.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in sents:\n",
    "    if sent.end > sent_idx[0]:\n",
    "        print(sent)\n",
    "        print()\n",
    "        del sent_idx[0]\n",
    "        if len(sent_idx) == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXTRA CREDIT:<br>Print the *sentence* that contains each found match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By diving I could evade the bullets and, swimming\n",
      "vigorously, reach the bank, take to the woods and get away home.  \n"
     ]
    }
   ],
   "source": [
    "for sent in sents:\n",
    "    if found_matches[0][1] < sent.end:\n",
    "        print(sent)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hunted man saw all this over his shoulder; he was now swimming\n",
      "vigorously with the current.  \n"
     ]
    }
   ],
   "source": [
    "for sent in sents:\n",
    "    if found_matches[1][1] < sent.end:\n",
    "        print(sent)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
